# SA-tensorflow
This is a fork of the soft attention tensorflow implementation from [SA-tensorflow](https://github.com/tsenghungchen/SA-tensorflow).

I slightly refined the code in Att.py for the new r1.0 tensorflow version. 

# Prerequisites
* Python 2.7
* [Tensorflow](https://www.tensorflow.org/) >= 1.0
* NumPy
* pandas
* keras

# References

[1] L. Yao, A. Torabi, K. Cho, N. Ballas, C. Pal, H. Larochelle, and A. Courville. 
Describing videos by exploiting temporal structure. arXiv:1502.08029v4, 2015.

[2] chen:acl11,
  title = "Collecting Highly Parallel Data for Paraphrase Evaluation",
  author = "David L. Chen and William B. Dolan",
  booktitle = "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-2011)",
  address = "Portland, OR",
  month = "June",
  year = 2011

[3] [Microsoft COCO Caption Evaluation](https://github.com/tylin/coco-caption)
